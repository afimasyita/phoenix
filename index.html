<!DOCTYPE html>
<head>
	<meta charset="UTF-8">
	
	<!-- Initialize the viewport -->
	<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
	
	<!-- Load the required dependencies: A-frame and AR.js -->
	<!--<script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script>
	<script src="https://aframe.io/releases/1.0.4/aframe.min.js"></script>-->
    	<script src="https://aframe.io/releases/0.9.2/aframe.min.js"></script>
    	<script src="https://cdn.rawgit.com/jeromeetienne/AR.js/master/aframe/build/aframe-ar.min.js"></script>
	
	
	<!-- This is to load the A-frame extras, that contain the required components that are used to show the animations -->
	<!-- of the 3D model of the robot -->
	<script src="https://rawgit.com/donmccurdy/aframe-extras/master/dist/aframe-extras.loaders.min.js"></script>
	
	<!--<script src="https://cdn.jsdelivr.net/npm/gl-bench/dist/gl-bench.min.js"></script>-->
	<!-- This is a hack because at the time of writing there are some distortions in the provided visuals until the
	system receives a resize event. The resize event must be triggered when everything has been loaded and the
	camera has been initialized. All the events I tried didn't work, so in the end I resorted using a 3 seconds
	time-out after the load event. When this problem will be fixed in the AR.js library, this hack won't be necessary
	anymore ! >.< -->
	
	<script>
	window.onload = function(){    
	      setTimeout(function(){
		var resizeEvent = window.document.createEvent('UIEvents'); 
		   resizeEvent.initUIEvent('resize', true, false, window, 0); 
			window.dispatchEvent(resizeEvent);
		}, 3000);
	};	
	</script>	
	
</head>
<body style='margin : 0px; overflow: hidden;'>
	
	<!-- ^.^ a-scene defines the scene that we are agoing to use. After arjs= there are various options that can be customized  -->
	<!-- ^.^ depending on your needs. For now just stick with these ones ^.^ -->
	
  <a-scene stats embedded arjs='sourceType: webcam; debugUIEnabled: false;'>
	<a-assets>
        	<audio id="sound" src="./sound/boombayah.mp3" preload="auto"></audio>
 	</a-assets>
		 <!-- ^.^ Here we load the asset of the robot, pointing to its file. A-frame works with GLTF and GLB models. ^.^ -->
		 <!-- ^.^ We define a name for this asset, that is "robot" ^.^ -->
	<a-assets>
		<a-asset-item id="robot" src="./assets/phoenix.glb"></a-asset-item>
   	</a-assets>
		 <!-- Defines the marker that we are going to use. Notice that we are not providing the image file, but the  -->
		 <!-- "compiled" .patt file that we got from the online tool. the marker MUST BE ACCESSIBLE VIA HTTPS -->
	    
		<a-marker preset='custom' type='pattern' url='./marker-patt/pattern-phoenix.patt'>
			<a-entity 
				gltf-model="#robot" 
				position="0 0 0"
				scale="0.25 0.25 0.25"
				animation-mixer soundhandler>
			 </a-entity>
         	</a-marker> 
	    		<a-entity sound="src: #sound" autoplay="false"></a-entity>
	    		
	<!-- Define the camera of the scene -->
         <a-entity camera></a-entity> 
    </a-scene>
	<script>
	     AFRAME.registerComponent('soundhandler', {
	    	tick: function () {
		   var entity = document.querySelector('[sound]');
		 	if (document.querySelector('a-marker').object3D.visible == true) {
		    	        entity.components.sound.playSound();
			} else {
		    		entity.components.sound.pauseSound();
				}
	     		}
		});
	</script>
	<!--<script>
		document.addEventListener('DOMContentLoaded', function() {
    		var scene = document.querySelector('a-scene');
    			var splash = document.querySelector('#splash');
    				scene.addEventListener('loaded', function (e) {
        		splash.style.display = 'none';
    			});
		});
	</script>-->
</body>
